{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for MNIST database recognizing\n",
    "\n",
    "This is a Neural Network developed without Machine Learning frameworks, using `numpy` and `matplotlib`, only for learning purposes. The objective of this project is practice Neural Networks Design principles and enhance knowledges on Machine Learning and Deep Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'warn', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from enum import Enum, unique\n",
    "np.seterr(all='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - MNIST Datasets download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.isdir(\"./datasets/\")):\n",
    "    os.mkdir(\"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/train-images-idx3-ubyte.gz\")):\n",
    "    mnist.download_file(\"train-images-idx3-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/train-labels-idx1-ubyte.gz\")):\n",
    "    mnist.download_file(\"train-labels-idx1-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/t10k-images-idx3-ubyte.gz\")):\n",
    "    mnist.download_file(\"t10k-images-idx3-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/t10k-labels-idx1-ubyte.gz\")):\n",
    "    mnist.download_file(\"t10k-labels-idx1-ubyte.gz\", \"./datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - MNIST Datasets Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000) (10, 60000) (784, 10000) (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "train_images_raw = mnist.train_images()\n",
    "train_labels_raw = mnist.train_labels()\n",
    "test_images_raw = mnist.test_images()\n",
    "test_labels_raw = mnist.test_labels()\n",
    "\n",
    "train_images = np.transpose(train_images_raw.reshape(train_images_raw.shape[0], train_images_raw.shape[1]*train_images_raw.shape[2]))\n",
    "\n",
    "train_labels = np.zeros((train_labels_raw.shape[0], train_labels_raw.max()+1))\n",
    "train_labels[np.arange(train_labels_raw.shape[0]), train_labels_raw] = 1\n",
    "train_labels = np.transpose(train_labels)\n",
    "\n",
    "test_images = np.transpose(test_images_raw.reshape(test_images_raw.shape[0], test_images_raw.shape[1]*test_images_raw.shape[2]))\n",
    "\n",
    "test_labels = np.zeros((test_labels_raw.shape[0], test_labels_raw.max()+1))\n",
    "test_labels[np.arange(test_labels_raw.shape[0]), test_labels_raw] = 1\n",
    "test_labels = np.transpose(test_labels)\n",
    "\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Activation functions enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "@unique\n",
    "class Activation(Enum):\n",
    "    SIGMOID = 1\n",
    "    TANH = 2\n",
    "    RELU = 3\n",
    "    LEAKY_RELU = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = train_images.shape[0]\n",
    "LAYERS = 3\n",
    "LAYER_UNITS = np.array([16, 10, 10], dtype=np.uint32)\n",
    "LAYER_ACTIVATIONS = np.array([Activation['RELU'], Activation['RELU'], Activation['RELU']])\n",
    "ALPHA = 10e-5\n",
    "LAMBDA_REG = 10e-4\n",
    "ITERATIONS = 1000\n",
    "EPSILON = 0.05\n",
    "\n",
    "EXAMPLES = train_images.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Activation functions and it's derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAKY_RELU_MULTIPLIER = 0.01\n",
    "\n",
    "def linear_func(X_matrix, W_matrix, b_array):\n",
    "    return np.dot(W_matrix, X_matrix) + b_array\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_threshold(z):\n",
    "    return np.round(z)\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def leaky_relu(z):\n",
    "    return np.maximum(LEAKY_RELU_MULTIPLIER * z, z)\n",
    "\n",
    "def derivative_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def derivative_tanh(z):\n",
    "    return 1 - (tanh(z)**2)\n",
    "\n",
    "def derivative_relu(z):\n",
    "    if(z < 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def derivative_leaky_relu(z):\n",
    "    if(z < 0):\n",
    "        return LEAKY_RELU_MULTIPLIER\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "derivative_relu = np.vectorize(derivative_relu)\n",
    "derivative_leaky_relu = np.vectorize(derivative_leaky_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Normalization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(X_matrix):\n",
    "    X_norm = np.zeros(X_matrix.shape)\n",
    "    for i in range(X_matrix.shape[0]):\n",
    "        #mu = np.mean(X_matrix[i])\n",
    "        #sigma = np.std(X_matrix[i])\n",
    "        X_norm[i] = X_matrix[i]/np.maximum(1, np.max(X_matrix[i]))\n",
    "    return X_norm\n",
    "\n",
    "def normalize_input(x_input, X_matrix):\n",
    "    x_norm = np.zeros(x_input.shape)\n",
    "    x_norm = x_input/np.maximum(1, np.max(X_matrix))\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Forward and Backward Propagation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_prop(A_previous, W_layer, b_layer, activationType = Activation['SIGMOID']):\n",
    "    Z_layer = linear_func(A_previous, W_layer, b_layer)\n",
    "    if (activationType == Activation['SIGMOID']):\n",
    "        A_layer = sigmoid(Z_layer)\n",
    "    elif (activationType == Activation['TANH']):\n",
    "        A_layer = tanh(Z_layer)\n",
    "    elif (activationType == Activation['RELU']):\n",
    "        A_layer = relu(Z_layer)\n",
    "    elif (activationType == Activation['LEAKY_RELU']):\n",
    "        A_layer = leaky_relu(Z_layer)\n",
    "    else:\n",
    "        A_layer = sigmoid(Z_layer)\n",
    "    return A_layer, Z_layer\n",
    "\n",
    "def back_prop(dA_layer, A_previous, Z_layer, W_layer, b_layer, activationType = Activation['SIGMOID']):\n",
    "    if (activationType == Activation['SIGMOID']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_sigmoid(Z_layer))\n",
    "    elif (activationType == Activation['TANH']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_tanh(Z_layer))\n",
    "    elif (activationType == Activation['RELU']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_relu(Z_layer))\n",
    "    elif (activationType == Activation['LEAKY_RELU']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_leaky_relu(Z_layer))\n",
    "    else:\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_sigmoid(Z_layer))\n",
    "    \n",
    "    dW_layer = np.dot(dZ_layer, np.transpose(A_previous))/dZ_layer.shape[1]\n",
    "    db_layer = np.sum(dZ_layer, axis = 1, keepdims = True)/dZ_layer.shape[1]\n",
    "    dA_previous = np.dot(np.transpose(W_layer), dZ_layer)\n",
    "\n",
    "    return dA_previous, dW_layer, db_layer   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, b,\n",
    "            layers = LAYERS,\n",
    "            layer_activations = LAYER_ACTIVATIONS):\n",
    "    A = X\n",
    "    for i in range(1, layers+1):\n",
    "        A, z = fwd_prop(A, W[i], b[i], layer_activations[i-1])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, y, W, b, lambda_reg = LAMBDA_REG):\n",
    "    y_prediction = predict(X, W, b)\n",
    "    regularization = 0\n",
    "    '''\n",
    "    try:\n",
    "        loss = - ((np.dot(y, np.transpose(np.log(y_prediction)))) + np.dot((1 - y), np.transpose(np.log(1 - y_prediction))))\n",
    "    except FloatingPointError:\n",
    "        y_prediction = abs(y_prediction-0.00000001)\n",
    "        loss = - ((np.dot(y, np.transpose(np.log(y_prediction)))) + np.dot((1 - y), np.transpose(np.log(1 - y_prediction))))\n",
    "    '''\n",
    "    loss = (1/2)*((y_prediction - y)**2)\n",
    "    #print(y_prediction.shape, y.shape, loss.shape)\n",
    "    for i in W:\n",
    "        regularization += np.sum(i**2)\n",
    "    cost = (np.sum(loss, axis = 1, keepdims=True)/y.shape[1]) + ((lambda_reg/(2*y.shape[1]))*regularization)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y,\n",
    "        W_previous = None,\n",
    "        b_previous = None,\n",
    "        features = FEATURES,\n",
    "        layers = LAYERS,\n",
    "        layer_units = LAYER_UNITS,\n",
    "        layer_activations = LAYER_ACTIVATIONS,\n",
    "        examples = EXAMPLES,\n",
    "        alpha = ALPHA,\n",
    "        lambda_reg = LAMBDA_REG,\n",
    "        iterations = ITERATIONS,\n",
    "        epsilon = EPSILON):\n",
    "    \n",
    "    W = {1: np.random.rand(layer_units[0], features)}\n",
    "    dW = {1: np.zeros([layer_units[0], features])}\n",
    "    b = {1:np.random.rand(layer_units[0], 1)}\n",
    "    db = {1: np.zeros([layer_units[0], 1])}\n",
    "    Z = {0: X}\n",
    "    A = {0: X}\n",
    "    dA = {0: np.array([])}\n",
    "    for k in range(layers - 1):\n",
    "        W[k+2] = np.random.rand(layer_units[k+1], layer_units[k])\n",
    "        dW[k+2] = np.zeros([layer_units[k+1], layer_units[k]])\n",
    "        b[k+2] = np.random.rand(layer_units[k+1], 1)\n",
    "        db[k+2] = np.zeros([layer_units[k+1], 1])\n",
    "        Z[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "        A[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "        dA[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "\n",
    "    if(W_previous != None and b_previous != None):\n",
    "        W = W_previous\n",
    "        b = b_previous\n",
    "\n",
    "    cost_points = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        for j in range(layers):\n",
    "            A[j+1], Z[j+1] = fwd_prop(A[j], W[j+1], b[j+1], layer_activations[j])\n",
    "\n",
    "        #if(layer_activations[len(layer_activations) - 1] == Activation[\"RELU\"]):\n",
    "            #A[layers] = derivative_relu(A[layers])\n",
    "        dA[layers] = A[layers] - y\n",
    "\n",
    "        for j in range(layers-1, -1, -1):\n",
    "            dA[j], dW[j+1], db[j+1] = back_prop(dA[j+1], A[j], Z[j+1], W[j+1], b[j+1], layer_activations[j])\n",
    "        \n",
    "        for j in range(1, layers+1):\n",
    "            W[j] = (W[j] * (1 - ((alpha*lambda_reg)/y.shape[1]))) - (alpha*dW[j])\n",
    "            b[j] = b[j] - (alpha*db[j])\n",
    "  \n",
    "        cost_points.append(cost(X, y, W, b))\n",
    "\n",
    "        #print(np.transpose(cost(X, y, W, b)))\n",
    "        #print(np.sum(dA[layers], axis = 1))\n",
    "        #print(Z[layers][:, 0])\n",
    "        \n",
    "        print(y[:, 0])\n",
    "        print()\n",
    "        #print()\n",
    "        #print(W, b)\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Training the N.N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.95290468]\n",
      " [-3.41233631]\n",
      " [-4.29219672]\n",
      " [-5.31430444]\n",
      " [-5.20654045]\n",
      " [-5.43307799]\n",
      " [-6.37137823]\n",
      " [-4.88459955]\n",
      " [-5.82314325]\n",
      " [-5.3812006 ]\n",
      " [-5.02909309]\n",
      " [-7.37281942]\n",
      " [-3.6590275 ]\n",
      " [-4.55511045]\n",
      " [-5.31291254]\n",
      " [-5.12707926]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-12.0251947 ]\n",
      " [ -7.24433378]\n",
      " [ -8.44303272]\n",
      " [-10.26560756]\n",
      " [-10.30876069]\n",
      " [-10.47130186]\n",
      " [-12.56598056]\n",
      " [ -9.72509452]\n",
      " [-11.23216009]\n",
      " [-10.6231329 ]\n",
      " [-10.00830218]\n",
      " [-14.13607022]\n",
      " [ -7.54035405]\n",
      " [ -9.2607034 ]\n",
      " [-10.42450702]\n",
      " [ -9.95644627]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-17.40550355]\n",
      " [-10.63976413]\n",
      " [-12.1209738 ]\n",
      " [-14.65268395]\n",
      " [-14.82964273]\n",
      " [-14.93548846]\n",
      " [-18.05363748]\n",
      " [-14.01405551]\n",
      " [-16.02483389]\n",
      " [-15.26762107]\n",
      " [-14.42029359]\n",
      " [-20.12831712]\n",
      " [-10.97936796]\n",
      " [-13.43029987]\n",
      " [-14.95357083]\n",
      " [-14.23561906]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-22.1730084 ]\n",
      " [-13.648996  ]\n",
      " [-15.38057724]\n",
      " [-18.54062709]\n",
      " [-18.83619226]\n",
      " [-18.89160984]\n",
      " [-22.9101175 ]\n",
      " [-17.81503328]\n",
      " [-20.27208245]\n",
      " [-19.38354463]\n",
      " [-18.33044609]\n",
      " [-25.4351113 ]\n",
      " [-14.02709892]\n",
      " [-17.12573716]\n",
      " [-18.9672278 ]\n",
      " [-18.02807451]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-26.4001114 ]\n",
      " [-16.31878203]\n",
      " [-18.27248139]\n",
      " [-21.98984772]\n",
      " [-22.39044463]\n",
      " [-22.40015503]\n",
      " [-27.20729235]\n",
      " [-21.18700705]\n",
      " [-24.03904052]\n",
      " [-23.03448166]\n",
      " [-21.79946433]\n",
      " [-30.13388362]\n",
      " [-16.73091289]\n",
      " [-20.40441497]\n",
      " [-22.52765227]\n",
      " [-21.39273174]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-30.15452257]\n",
      " [-18.69272858]\n",
      " [-20.84391344]\n",
      " [-25.05662773]\n",
      " [-25.55017441]\n",
      " [-25.51862204]\n",
      " [-31.01521355]\n",
      " [-24.18492998]\n",
      " [-27.38698647]\n",
      " [-26.28010691]\n",
      " [-24.88391944]\n",
      " [-34.29631801]\n",
      " [-19.13498703]\n",
      " [-23.31985508]\n",
      " [-25.69261595]\n",
      " [-24.38452439]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-33.49653478]\n",
      " [-20.81045219]\n",
      " [-23.13778908]\n",
      " [-27.79222907]\n",
      " [-28.36755782]\n",
      " [-28.29899872]\n",
      " [-34.39548618]\n",
      " [-26.85885159]\n",
      " [-30.37145677]\n",
      " [-29.17412483]\n",
      " [-27.63513451]\n",
      " [-37.98434689]\n",
      " [-21.27946033]\n",
      " [-25.92061514]\n",
      " [-28.5146921 ]\n",
      " [-27.05341604]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-36.48032806]\n",
      " [-22.70699198]\n",
      " [-25.19205632]\n",
      " [-30.24171002]\n",
      " [-30.88965801]\n",
      " [-30.78757742]\n",
      " [-37.3991666 ]\n",
      " [-29.25300204]\n",
      " [-33.04082577]\n",
      " [-31.76475976]\n",
      " [-30.09880912]\n",
      " [-41.25086039]\n",
      " [-23.19984154]\n",
      " [-28.24985252]\n",
      " [-31.04003715]\n",
      " [-29.44350718]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-39.15434065]\n",
      " [-24.41293633]\n",
      " [-27.03986091]\n",
      " [-32.4447229 ]\n",
      " [-33.15635759]\n",
      " [-33.0237711 ]\n",
      " [-40.08083148]\n",
      " [-31.40616328]\n",
      " [-35.4366489 ]\n",
      " [-34.0931497 ]\n",
      " [-32.31453747]\n",
      " [-44.15247961]\n",
      " [-24.92711899]\n",
      " [-30.34496185]\n",
      " [-33.30861153]\n",
      " [-31.59331436]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-41.56046182]\n",
      " [-25.95473445]\n",
      " [-28.7098525 ]\n",
      " [-34.43531433]\n",
      " [-35.20197927]\n",
      " [-35.04299187]\n",
      " [-42.47769483]\n",
      " [-33.35113318]\n",
      " [-37.59610983]\n",
      " [-36.19506503]\n",
      " [-34.31666827]\n",
      " [-46.74027274]\n",
      " [-26.48808636]\n",
      " [-32.23838028]\n",
      " [-35.35573781]\n",
      " [-33.53624157]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-43.73508215]\n",
      " [-27.35492722]\n",
      " [-30.22644874]\n",
      " [-36.24249814]\n",
      " [-37.05734728]\n",
      " [-36.87476479]\n",
      " [-44.63339633]\n",
      " [-35.11650376]\n",
      " [-39.55220152]\n",
      " [-38.10146753]\n",
      " [-36.13438338]\n",
      " [-49.05492095]\n",
      " [-27.90560311]\n",
      " [-33.95773467]\n",
      " [-37.21024425]\n",
      " [-35.30068506]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-45.71054023]\n",
      " [-28.63262723]\n",
      " [-31.61033291]\n",
      " [-37.89094542]\n",
      " [-38.74746471]\n",
      " [-38.54400471]\n",
      " [-46.57864545]\n",
      " [-36.72666226]\n",
      " [-41.33176325]\n",
      " [-39.83849876]\n",
      " [-37.79250967]\n",
      " [-51.13171513]\n",
      " [-29.19899806]\n",
      " [-35.52649236]\n",
      " [-38.89860961]\n",
      " [-36.91073426]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-47.51235137]\n",
      " [-29.80400236]\n",
      " [-32.87904337]\n",
      " [-39.40150106]\n",
      " [-40.29412313]\n",
      " [-40.07264281]\n",
      " [-48.34423734]\n",
      " [-38.20181938]\n",
      " [-42.95832651]\n",
      " [-41.42849759]\n",
      " [-39.31221279]\n",
      " [-53.00084144]\n",
      " [-30.38469595]\n",
      " [-36.9647016 ]\n",
      " [-40.44360699]\n",
      " [-38.38672273]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-49.16124514]\n",
      " [-30.8827343 ]\n",
      " [-34.04739521]\n",
      " [-40.79191772]\n",
      " [-41.71533481]\n",
      " [-41.47866351]\n",
      " [-49.9450711 ]\n",
      " [-39.55941947]\n",
      " [-44.45152233]\n",
      " [-42.89033588]\n",
      " [-40.71142592]\n",
      " [-54.68971499]\n",
      " [-31.47653129]\n",
      " [-38.28910902]\n",
      " [-41.86220889]\n",
      " [-39.74587734]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-50.67902506]\n",
      " [-31.88040045]\n",
      " [-35.12791657]\n",
      " [-42.07735222]\n",
      " [-43.02776281]\n",
      " [-42.77675472]\n",
      " [-51.4062016 ]\n",
      " [-40.81435612]\n",
      " [-45.82738331]\n",
      " [-44.24030999]\n",
      " [-42.00513491]\n",
      " [-56.22052793]\n",
      " [-32.48621093]\n",
      " [-39.51374639]\n",
      " [-43.17228967]\n",
      " [-41.00287718]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-52.07927362]\n",
      " [-32.80670757]\n",
      " [-36.1311304 ]\n",
      " [-43.27048003]\n",
      " [-44.24419707]\n",
      " [-43.98039281]\n",
      " [-52.74564494]\n",
      " [-41.97920302]\n",
      " [-47.10181656]\n",
      " [-45.49218783]\n",
      " [-43.20611384]\n",
      " [-57.62015064]\n",
      " [-33.42361679]\n",
      " [-40.65078431]\n",
      " [-44.3856977 ]\n",
      " [-42.1697819 ]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-53.37424812]\n",
      " [-33.66983152]\n",
      " [-37.06589803]\n",
      " [-44.38156286]\n",
      " [-45.37471617]\n",
      " [-45.10036864]\n",
      " [-53.98302824]\n",
      " [-43.06387115]\n",
      " [-48.28388955]\n",
      " [-46.65608141]\n",
      " [-44.32492833]\n",
      " [-58.90343443]\n",
      " [-34.29703229]\n",
      " [-41.71026161]\n",
      " [-45.51389689]\n",
      " [-43.25697581]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-54.57768721]\n",
      " [-34.47685338]\n",
      " [-37.93988216]\n",
      " [-45.41972348]\n",
      " [-46.42862402]\n",
      " [-46.14630964]\n",
      " [-55.12429527]\n",
      " [-44.0776044 ]\n",
      " [-49.38229101]\n",
      " [-47.74268236]\n",
      " [-45.37066066]\n",
      " [-60.08331617]\n",
      " [-35.11359908]\n",
      " [-42.7007193 ]\n",
      " [-46.56588438]\n",
      " [-44.27356718]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-55.69762873]\n",
      " [-35.23382186]\n",
      " [-38.75965086]\n",
      " [-46.39290781]\n",
      " [-47.4141882 ]\n",
      " [-47.12644685]\n",
      " [-56.18379515]\n",
      " [-45.02767905]\n",
      " [-50.40792153]\n",
      " [-48.75894083]\n",
      " [-46.35109104]\n",
      " [-61.1770498 ]\n",
      " [-35.87948099]\n",
      " [-43.62957946]\n",
      " [-47.55037742]\n",
      " [-45.22701498]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-56.74630781]\n",
      " [-35.94593108]\n",
      " [-39.530811  ]\n",
      " [-47.30796086]\n",
      " [-48.33844556]\n",
      " [-48.04737761]\n",
      " [-57.16978991]\n",
      " [-45.92064878]\n",
      " [-51.36856941]\n",
      " [-49.71394339]\n",
      " [-47.27326708]\n",
      " [-62.19646636]\n",
      " [-36.59990214]\n",
      " [-44.50323265]\n",
      " [-48.47368937]\n",
      " [-46.12392135]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-57.73008297]\n",
      " [-36.61757709]\n",
      " [-40.25813342]\n",
      " [-48.17044606]\n",
      " [-49.20839303]\n",
      " [-48.9145782 ]\n",
      " [-58.09169894]\n",
      " [-46.76249009]\n",
      " [-52.2720956 ]\n",
      " [-50.61186165]\n",
      " [-48.1429248 ]\n",
      " [-63.14797702]\n",
      " [-37.27933881]\n",
      " [-45.32715224]\n",
      " [-49.34352497]\n",
      " [-46.96977416]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-58.65635142]\n",
      " [-37.25261977]\n",
      " [-40.94581475]\n",
      " [-48.98562893]\n",
      " [-50.02911024]\n",
      " [-49.73372096]\n",
      " [-58.95551717]\n",
      " [-47.55795756]\n",
      " [-53.12211129]\n",
      " [-51.45936013]\n",
      " [-48.96486077]\n",
      " [-64.03750059]\n",
      " [-37.92170795]\n",
      " [-46.10614054]\n",
      " [-50.1635621 ]\n",
      " [-47.76952901]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-59.52935404]\n",
      " [-37.85446057]\n",
      " [-41.59752055]\n",
      " [-49.75751685]\n",
      " [-50.80497359]\n",
      " [-50.50891992]\n",
      " [-59.76993427]\n",
      " [-48.31144076]\n",
      " [-53.92487745]\n",
      " [-52.26066889]\n",
      " [-49.74368972]\n",
      " [-64.8727329 ]\n",
      " [-38.5304694 ]\n",
      " [-46.84435798]\n",
      " [-50.938471  ]\n",
      " [-48.5274675 ]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "[[-60.35386931]\n",
      " [-38.42607089]\n",
      " [-42.21647927]\n",
      " [-50.49005571]\n",
      " [-51.54007062]\n",
      " [-51.24401082]\n",
      " [-60.53682155]\n",
      " [-49.02671864]\n",
      " [-54.68487304]\n",
      " [-53.0206864 ]\n",
      " [-50.48295762]\n",
      " [-65.65578039]\n",
      " [-39.10861288]\n",
      " [-47.54547237]\n",
      " [-51.6734308 ]\n",
      " [-49.24721766]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\andre\\Documents\\GitHub\\Neural-Net-MNIST-Recognizer\\Neural-Net-MNIST-Recognizer.ipynb Célula: 25\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=0'>1</a>\u001b[0m test_images_normalized \u001b[39m=\u001b[39m normalize_dataset(test_images)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=1'>2</a>\u001b[0m W_final, b_final \u001b[39m=\u001b[39m fit(test_images_normalized, test_labels)\n",
      "\u001b[1;32me:\\andre\\Documents\\GitHub\\Neural-Net-MNIST-Recognizer\\Neural-Net-MNIST-Recognizer.ipynb Célula: 25\u001b[0m in \u001b[0;36mfit\u001b[1;34m(X, y, W_previous, b_previous, features, layers, layer_units, layer_activations, examples, alpha, lambda_reg, iterations, epsilon)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=42'>43</a>\u001b[0m dA[layers] \u001b[39m=\u001b[39m A[layers] \u001b[39m-\u001b[39m y\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=44'>45</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(layers\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=45'>46</a>\u001b[0m     dA[j], dW[j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m], db[j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m back_prop(dA[j\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m], A[j], Z[j\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m], W[j\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m], b[j\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m], layer_activations[j])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, layers\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=49'>50</a>\u001b[0m     W[j] \u001b[39m=\u001b[39m (W[j] \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ((alpha\u001b[39m*\u001b[39mlambda_reg)\u001b[39m/\u001b[39my\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))) \u001b[39m#- (alpha*dW[j])\u001b[39;00m\n",
      "\u001b[1;32me:\\andre\\Documents\\GitHub\\Neural-Net-MNIST-Recognizer\\Neural-Net-MNIST-Recognizer.ipynb Célula: 25\u001b[0m in \u001b[0;36mback_prop\u001b[1;34m(dA_layer, A_previous, Z_layer, W_layer, b_layer, activationType)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=18'>19</a>\u001b[0m     dZ_layer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(dA_layer, derivative_tanh(Z_layer))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=19'>20</a>\u001b[0m \u001b[39melif\u001b[39;00m (activationType \u001b[39m==\u001b[39m Activation[\u001b[39m'\u001b[39m\u001b[39mRELU\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=20'>21</a>\u001b[0m     dZ_layer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(dA_layer, derivative_relu(Z_layer))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=21'>22</a>\u001b[0m \u001b[39melif\u001b[39;00m (activationType \u001b[39m==\u001b[39m Activation[\u001b[39m'\u001b[39m\u001b[39mLEAKY_RELU\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=22'>23</a>\u001b[0m     dZ_layer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(dA_layer, derivative_leaky_relu(Z_layer))\n",
      "File \u001b[1;32md:\\Programas\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:2163\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2160\u001b[0m     vargs \u001b[39m=\u001b[39m [args[_i] \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m inds]\n\u001b[0;32m   2161\u001b[0m     vargs\u001b[39m.\u001b[39mextend([kwargs[_n] \u001b[39mfor\u001b[39;00m _n \u001b[39min\u001b[39;00m names])\n\u001b[1;32m-> 2163\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_call(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49mvargs)\n",
      "File \u001b[1;32md:\\Programas\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:2246\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[0;32m   2244\u001b[0m inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[1;32m-> 2246\u001b[0m outputs \u001b[39m=\u001b[39m ufunc(\u001b[39m*\u001b[39;49minputs)\n\u001b[0;32m   2248\u001b[0m \u001b[39mif\u001b[39;00m ufunc\u001b[39m.\u001b[39mnout \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2249\u001b[0m     res \u001b[39m=\u001b[39m asanyarray(outputs, dtype\u001b[39m=\u001b[39motypes[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;32me:\\andre\\Documents\\GitHub\\Neural-Net-MNIST-Recognizer\\Neural-Net-MNIST-Recognizer.ipynb Célula: 25\u001b[0m in \u001b[0;36mderivative_relu\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mderivative_tanh\u001b[39m(z):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m (tanh(z)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mderivative_relu\u001b[39m(z):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=27'>28</a>\u001b[0m     \u001b[39mif\u001b[39;00m(z \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/andre/Documents/GitHub/Neural-Net-MNIST-Recognizer/Neural-Net-MNIST-Recognizer.ipynb#ch0000025?line=28'>29</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_images_normalized = normalize_dataset(test_images)\n",
    "W_final, b_final = fit(test_images_normalized, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 - Testing the N.N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_save = W_final\n",
    "b_save = b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = int(np.round(np.random.rand()*len(test_images_raw)))\n",
    "\n",
    "plt.imshow(test_images_raw[index], cmap='magma')\n",
    "print(test_labels_raw[index])\n",
    "print()\n",
    "test_sample = normalize_input(test_images[:, index].reshape(test_images[:, index].shape[0], 1), test_images)\n",
    "print(np.transpose(predict(test_sample, W_save, b_save)))\n",
    "print()\n",
    "print(test_labels[:, index])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "427b8541cfc07e6fbe7ab4a5298567b1b3022ff2b70fdb07d029f33f0434686a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
