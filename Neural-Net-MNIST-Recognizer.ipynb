{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for MNIST database recognizing\n",
    "\n",
    "This is a Neural Network developed without Machine Learning frameworks, using `numpy` and `matplotlib`, only for learning purposes. The objective of this project is practice Neural Networks Design principles and enhance knowledges on Machine Learning and Deep Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Library imports\n",
    "\n",
    "Using `numpy`, `matplotlib`, `mnist` (Anaconda version), `os` and `enum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(all='warn')\n",
    "\n",
    "import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from enum import Enum, unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - MNIST Datasets download\n",
    "\n",
    "Datasets download made with `mnist` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.isdir(\"./datasets/\")):\n",
    "    os.mkdir(\"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/train-images-idx3-ubyte.gz\")):\n",
    "    mnist.download_file(\"train-images-idx3-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/train-labels-idx1-ubyte.gz\")):\n",
    "    mnist.download_file(\"train-labels-idx1-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/t10k-images-idx3-ubyte.gz\")):\n",
    "    mnist.download_file(\"t10k-images-idx3-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/t10k-labels-idx1-ubyte.gz\")):\n",
    "    mnist.download_file(\"t10k-labels-idx1-ubyte.gz\", \"./datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - MNIST Datasets Load\n",
    "\n",
    "Load and reshaping of the datasets. Labels converted to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_raw = mnist.train_images()\n",
    "train_labels_raw = mnist.train_labels()\n",
    "test_images_raw = mnist.test_images()\n",
    "test_labels_raw = mnist.test_labels()\n",
    "\n",
    "train_images = np.transpose(train_images_raw.reshape(train_images_raw.shape[0], train_images_raw.shape[1]*train_images_raw.shape[2]))\n",
    "\n",
    "train_labels = np.zeros((train_labels_raw.shape[0], train_labels_raw.max()+1))\n",
    "train_labels[np.arange(train_labels_raw.shape[0]), train_labels_raw] = 1\n",
    "train_labels = np.transpose(train_labels)\n",
    "\n",
    "test_images = np.transpose(test_images_raw.reshape(test_images_raw.shape[0], test_images_raw.shape[1]*test_images_raw.shape[2]))\n",
    "\n",
    "test_labels = np.zeros((test_labels_raw.shape[0], test_labels_raw.max()+1))\n",
    "test_labels[np.arange(test_labels_raw.shape[0]), test_labels_raw] = 1\n",
    "test_labels = np.transpose(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Activation functions enum\n",
    "\n",
    "Activation enum. It's used to select whether activation function will be applied on each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "@unique\n",
    "class Activation(Enum):\n",
    "    SIGMOID = 1\n",
    "    TANH = 2\n",
    "    RELU = 3\n",
    "    LEAKY_RELU = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Hyperparameters\n",
    "\n",
    "Hyperparameter constants. It's adjusted and applied on functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = train_images.shape[0]\n",
    "\n",
    "LAYER_UNITS = np.array([32, 32, 16, 10], dtype=np.uint32)\n",
    "LAYER_ACTIVATIONS = np.array([Activation['RELU'], Activation['RELU'], Activation['TANH'], Activation['SIGMOID']])\n",
    "LAYERS = LAYER_UNITS.shape[0]\n",
    "ALPHA = 8.5*10e-5\n",
    "LAMBDA_REG = 10e-5\n",
    "EPOCHS = 20\n",
    "EPSILON = 10e-8\n",
    "MINIBATCH_SIZE = 512\n",
    "LEARNING_DECAY = 0.9\n",
    "BETA_MOMENTUM = 0.9\n",
    "BETA_RMS = 0.999\n",
    "\n",
    "EXAMPLES = train_images.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Activation functions and it's derivatives\n",
    "\n",
    "Linear function, Sigmoid, Tanh, ReLU and Leaky ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAKY_RELU_MULTIPLIER = 0.01\n",
    "\n",
    "def linear_func(X_matrix, W_matrix, b_array):\n",
    "    return np.dot(W_matrix, X_matrix) + b_array\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_threshold(z):\n",
    "    return np.round(z)\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def leaky_relu(z):\n",
    "    return np.maximum(LEAKY_RELU_MULTIPLIER * z, z)\n",
    "\n",
    "def derivative_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def derivative_tanh(z):\n",
    "    return 1 - (tanh(z)**2)\n",
    "\n",
    "def derivative_relu(z):\n",
    "    if(z < 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def derivative_leaky_relu(z):\n",
    "    if(z < 0):\n",
    "        return LEAKY_RELU_MULTIPLIER\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "derivative_relu = np.vectorize(derivative_relu)\n",
    "derivative_leaky_relu = np.vectorize(derivative_leaky_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Normalization functions\n",
    "\n",
    "For some reason, normalization with mean and standard was buggy, so... I just divided each feature by it's maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(X_matrix):\n",
    "    X_norm = np.zeros(X_matrix.shape)\n",
    "    for i in range(X_matrix.shape[0]):\n",
    "        X_norm[i] = X_matrix[i]/np.maximum(1, np.max(X_matrix[i]))\n",
    "    return X_norm\n",
    "\n",
    "def normalize_input(x_input, X_matrix):\n",
    "    x_norm = np.zeros(x_input.shape)\n",
    "    x_norm = x_input/np.maximum(1, np.max(X_matrix))\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Forward and Backward Propagation Functions\n",
    "\n",
    "Fwdprop and backprop functions (optimizations are done in fit function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_prop(A_previous, W_layer, b_layer, activationType = Activation['SIGMOID']):\n",
    "    Z_layer = linear_func(A_previous, W_layer, b_layer)\n",
    "    if (activationType == Activation['SIGMOID']):\n",
    "        A_layer = sigmoid(Z_layer)\n",
    "    elif (activationType == Activation['TANH']):\n",
    "        A_layer = tanh(Z_layer)\n",
    "    elif (activationType == Activation['RELU']):\n",
    "        A_layer = relu(Z_layer)\n",
    "    elif (activationType == Activation['LEAKY_RELU']):\n",
    "        A_layer = leaky_relu(Z_layer)\n",
    "    else:\n",
    "        A_layer = sigmoid(Z_layer)\n",
    "    return A_layer, Z_layer\n",
    "\n",
    "def back_prop(dA_layer, A_previous, Z_layer, W_layer, b_layer, activationType = Activation['SIGMOID']):\n",
    "    if (activationType == Activation['SIGMOID']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_sigmoid(Z_layer))\n",
    "    elif (activationType == Activation['TANH']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_tanh(Z_layer))\n",
    "    elif (activationType == Activation['RELU']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_relu(Z_layer))\n",
    "    elif (activationType == Activation['LEAKY_RELU']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_leaky_relu(Z_layer))\n",
    "    else:\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_sigmoid(Z_layer))\n",
    "    \n",
    "    dW_layer = np.dot(dZ_layer, np.transpose(A_previous))/dZ_layer.shape[1]\n",
    "    db_layer = np.sum(dZ_layer, axis = 1, keepdims = True)/dZ_layer.shape[1]\n",
    "    dA_previous = np.dot(np.transpose(W_layer), dZ_layer)\n",
    "\n",
    "    return dA_previous, dW_layer, db_layer   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Predict Function\n",
    "\n",
    "Prediction based on calculated weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, b,\n",
    "            layers = LAYERS,\n",
    "            layer_activations = LAYER_ACTIVATIONS):\n",
    "    A = X\n",
    "    for i in range(1, layers+1):\n",
    "        A, z = fwd_prop(A, W[i], b[i], layer_activations[i-1])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Cost function\n",
    "\n",
    "For some reason, $- y \\cdot \\text{log}(y_{prediction}) - (1 - y) \\cdot \\text{log}(1 - y_{prediction})$ didn't work so well, so I used mean squared error instead.\n",
    "\n",
    "This cost function doesn't affect neither the propagation functions, nor the fit function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, y, W, b, lambda_reg = LAMBDA_REG):\n",
    "    y_prediction = predict(X, W, b)\n",
    "    regularization = 0\n",
    "    loss = (1/2)*((y_prediction - y)**2)\n",
    "    for i in W:\n",
    "        regularization += np.sum(i**2)\n",
    "    cost = (np.sum(loss, axis = 1, keepdims=True)/y.shape[1]) + ((lambda_reg/(2*y.shape[1]))*regularization)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Fit Function\n",
    "\n",
    "Fit function is implemented with optimization. (I'm using Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y,\n",
    "        W_previous = None,\n",
    "        b_previous = None,\n",
    "        features = FEATURES,\n",
    "        layers = LAYERS,\n",
    "        layer_units = LAYER_UNITS,\n",
    "        layer_activations = LAYER_ACTIVATIONS,\n",
    "        examples = EXAMPLES,\n",
    "        alpha = ALPHA,\n",
    "        learning_decay = LEARNING_DECAY,\n",
    "        lambda_reg = LAMBDA_REG,\n",
    "        epochs = EPOCHS,\n",
    "        epsilon = EPSILON,\n",
    "        mb_size = MINIBATCH_SIZE,\n",
    "        beta_momentum = BETA_MOMENTUM,\n",
    "        beta_rms = BETA_RMS):\n",
    "    \n",
    "    W = {1: np.random.randn(layer_units[0], features) * np.sqrt(2/features)}\n",
    "    dW = {1: np.zeros([layer_units[0], features])}\n",
    "    b = {1:np.random.randn(layer_units[0], 1)}\n",
    "    db = {1: np.zeros([layer_units[0], 1])}\n",
    "    Z = {0: X}\n",
    "    A = {0: X}\n",
    "    dA = {0: np.array([])}\n",
    "    for k in range(layers - 1):\n",
    "        W[k+2] = np.random.randn(layer_units[k+1], layer_units[k]) * np.sqrt(1/layer_units[k])\n",
    "        dW[k+2] = np.zeros([layer_units[k+1], layer_units[k]])\n",
    "        b[k+2] = np.random.randn(layer_units[k+1], 1)\n",
    "        db[k+2] = np.zeros([layer_units[k+1], 1])\n",
    "        Z[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "        A[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "        dA[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "\n",
    "    if(W_previous != None and b_previous != None):\n",
    "        W = W_previous\n",
    "        b = b_previous\n",
    "\n",
    "    alpha_decay = alpha\n",
    "\n",
    "    cost_points = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        vdW = {}\n",
    "        vdb = {}\n",
    "        sdW = {}\n",
    "        sdb = {}\n",
    "        for v in range(1, layers+1):\n",
    "            vdW[v] = np.zeros(dW[v].shape)\n",
    "            vdb[v] = np.zeros(db[v].shape)\n",
    "            sdW[v] = np.zeros(dW[v].shape)\n",
    "            sdb[v] = np.zeros(db[v].shape)\n",
    "\n",
    "        print(f\"\\rEpoch {i+1} of {epochs}\", end=\"\")\n",
    "\n",
    "        for k in range(int(np.ceil(A[0].shape[1]/mb_size))):\n",
    "\n",
    "            mb_start = k*mb_size\n",
    "            mb_end = np.minimum((k+1)*mb_size, A[0].shape[1])\n",
    "\n",
    "            for j in range(layers):\n",
    "                if(j == 0):\n",
    "                    A[j+1], Z[j+1] = fwd_prop(A[j][:, mb_start:mb_end], W[j+1], b[j+1], layer_activations[j])\n",
    "                else:\n",
    "                    A[j+1], Z[j+1] = fwd_prop(A[j], W[j+1], b[j+1], layer_activations[j])\n",
    "\n",
    "            dA[layers] = - (y[:, mb_start:mb_end]/A[layers]) + ((1-y[:, mb_start:mb_end])/(1-A[layers]))\n",
    "\n",
    "            for j in range(layers-1, -1, -1):\n",
    "                if(j == 0):\n",
    "                    dA[j], dW[j+1], db[j+1] = back_prop(dA[j+1], A[j][:, mb_start:mb_end], Z[j+1], W[j+1], b[j+1], layer_activations[j])\n",
    "                else:\n",
    "                    dA[j], dW[j+1], db[j+1] = back_prop(dA[j+1], A[j], Z[j+1], W[j+1], b[j+1], layer_activations[j])\n",
    "            \n",
    "            for j in range(1, layers+1):\n",
    "                vdW[j] = ((beta_momentum * vdW[j]) + ((1 - beta_momentum) * dW[j]))/(1 + (beta_momentum**(k+1)))\n",
    "                vdb[j] = ((beta_momentum * vdb[j]) + ((1 - beta_momentum) * db[j]))/(1 + (beta_momentum**(k+1)))\n",
    "                sdW[j] = ((beta_rms * sdW[j]) + ((1 - beta_rms) * dW[j]**2))/(1 + (beta_rms**(k+1)))\n",
    "                sdb[j] = ((beta_rms * sdb[j]) + ((1 - beta_rms) * db[j]**2))/(1 + (beta_rms**(k+1)))\n",
    "                W[j] = (W[j] * (1 - ((alpha_decay*lambda_reg)/y.shape[1]))) - (alpha_decay*(vdW[j]/(epsilon + np.sqrt(sdW[j]))))\n",
    "                b[j] = b[j] - (alpha_decay*(vdb[j]/(epsilon + np.sqrt(sdb[j]))))\n",
    "    \n",
    "            cost_points.append(cost(X[:, mb_start:mb_end], y[:, mb_start:mb_end], W, b))\n",
    "        \n",
    "        alpha_decay = alpha*(learning_decay**(i+1))\n",
    "\n",
    "        #print(np.transpose(cost_points[len(cost_points) - 1]))\n",
    "    \n",
    "    print(\"\\r                        \", end=\"\")\n",
    "    print(\"\\rDone.\")\n",
    "\n",
    "    return W, b, cost_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Training the N.N.\n",
    "\n",
    "Running fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.                   \n"
     ]
    }
   ],
   "source": [
    "train_images_normalized = normalize_dataset(train_images)\n",
    "W_final, b_final, cost_final = fit(train_images_normalized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c4002e6d60>]"
      ]
     },
     "execution_count": 1155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_final = np.array(cost_final).reshape(-1, 10)\n",
    "#print(cost_final[:, 0])\n",
    "plt.plot(np.arange(len(cost_final)), cost_final[:, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 - Saving Checkpoint\n",
    "\n",
    "Here we can save the results of fitting. We can run a new fit not losing previous fit in `W_save` and `b_save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_save = W_final\n",
    "b_save = b_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ACTIVE_SAVING_CHECKPOINT` == `True`, `W_save` and `b_save` are saved on `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVE_SAVING_CHECKPOINT = False\n",
    "\n",
    "if(ACTIVE_SAVING_CHECKPOINT):\n",
    "    if(not os.path.isdir(\"./training-checkpoint/\")):\n",
    "        os.mkdir(\"./training-checkpoint/\")\n",
    "\n",
    "    for i in W_save:\n",
    "        np.savetxt(f'./training-checkpoint/w{i}.csv', W_save[i], delimiter=',')\n",
    "    for i in b_save:\n",
    "        np.savetxt(f'./training-checkpoint/b{i}.csv', b_save[i], delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 - Loading Checkpoint\n",
    "\n",
    "If `ACTIVE_LOADING_CHECKPOINT` == `True`, `W_save` and `b_save` are loaded with `.csv` files content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVE_LOADING_CHECKPOINT = False\n",
    "\n",
    "if(ACTIVE_LOADING_CHECKPOINT):\n",
    "    W_save = {}\n",
    "    b_save = {}\n",
    "    for i in range(1, LAYERS + 1):\n",
    "        W_save[i] = np.loadtxt(f'./training-checkpoint/w{i}.csv', delimiter=',')\n",
    "        b_save[i] = np.loadtxt(f'./training-checkpoint/b{i}.csv', delimiter=',')\n",
    "        b_save[i] = np.reshape(b_save[i], (b_save[i].shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 - Measuring accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set prediction: 92.65 %\n"
     ]
    }
   ],
   "source": [
    "test_images_normalized = normalize_input(test_images, train_images)\n",
    "test_outputs = np.transpose(sigmoid_threshold(np.transpose(predict(test_images_normalized, W_save, b_save))))\n",
    "test_comparison = np.array([np.array_equal(test_outputs[:, i], test_labels[:, i]) for i in range(test_outputs.shape[1])])\n",
    "test_accuracy = np.sum(test_comparison)*100/test_comparison.shape[0]\n",
    "print(f\"Accuracy on test set prediction: {test_accuracy} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 - Measuring accuracy on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set prediction: 94.07666666666667 %\n"
     ]
    }
   ],
   "source": [
    "train_images_normalized = normalize_dataset(train_images)\n",
    "train_outputs = np.transpose(sigmoid_threshold(np.transpose(predict(train_images_normalized, W_save, b_save))))\n",
    "train_comparison = np.array([np.array_equal(train_outputs[:, i], train_labels[:, i]) for i in range(train_outputs.shape[1])])\n",
    "train_accuracy = np.sum(train_comparison)*100/train_comparison.shape[0]\n",
    "print(f\"Accuracy on train set prediction: {train_accuracy} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17 - Test playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saída esperada: 0\n",
      "Saída predita: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = int(np.round(np.random.rand()*len(test_images_raw)))\n",
    "\n",
    "plt.imshow(test_images_raw[index], cmap='magma')\n",
    "test_sample = normalize_input(test_images[:, index].reshape(test_images[:, index].shape[0], 1), train_images)\n",
    "test_predict = sigmoid_threshold(np.transpose(predict(test_sample, W_save, b_save)))\n",
    "print(f\"Saída esperada: {test_labels_raw[index]}\")\n",
    "for i in range(len(test_predict[0])):\n",
    "    if test_predict[0, i] == 1:\n",
    "        print(f\"Saída predita: {i}\")\n",
    "        break\n",
    "    if(i == 9):\n",
    "        print(f\"Sem predição válida.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "427b8541cfc07e6fbe7ab4a5298567b1b3022ff2b70fdb07d029f33f0434686a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
