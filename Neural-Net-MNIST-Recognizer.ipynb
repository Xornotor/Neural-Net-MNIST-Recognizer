{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for MNIST database recognizing\n",
    "\n",
    "This is a Neural Network developed without Machine Learning frameworks, using `numpy` and `matplotlib`, only for learning purposes. The objective of this project is practice Neural Networks Design principles and enhance knowledges on Machine Learning and Deep Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from enum import Enum, unique\n",
    "np.seterr(all='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - MNIST Datasets download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.isdir(\"./datasets/\")):\n",
    "    os.mkdir(\"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/train-images-idx3-ubyte.gz\")):\n",
    "    mnist.download_file(\"train-images-idx3-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/train-labels-idx1-ubyte.gz\")):\n",
    "    mnist.download_file(\"train-labels-idx1-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/t10k-images-idx3-ubyte.gz\")):\n",
    "    mnist.download_file(\"t10k-images-idx3-ubyte.gz\", \"./datasets\")\n",
    "if(not os.path.isfile(\"./datasets/t10k-labels-idx1-ubyte.gz\")):\n",
    "    mnist.download_file(\"t10k-labels-idx1-ubyte.gz\", \"./datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - MNIST Datasets Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000) (10, 60000) (784, 10000) (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "train_images_raw = mnist.train_images()\n",
    "train_labels_raw = mnist.train_labels()\n",
    "test_images_raw = mnist.test_images()\n",
    "test_labels_raw = mnist.test_labels()\n",
    "\n",
    "train_images = np.transpose(train_images_raw.reshape(train_images_raw.shape[0], train_images_raw.shape[1]*train_images_raw.shape[2]))\n",
    "\n",
    "train_labels = np.zeros((train_labels_raw.shape[0], train_labels_raw.max()+1))\n",
    "train_labels[np.arange(train_labels_raw.shape[0]), train_labels_raw] = 1\n",
    "train_labels = np.transpose(train_labels)\n",
    "\n",
    "test_images = np.transpose(test_images_raw.reshape(test_images_raw.shape[0], test_images_raw.shape[1]*test_images_raw.shape[2]))\n",
    "\n",
    "test_labels = np.zeros((test_labels_raw.shape[0], test_labels_raw.max()+1))\n",
    "test_labels[np.arange(test_labels_raw.shape[0]), test_labels_raw] = 1\n",
    "test_labels = np.transpose(test_labels)\n",
    "\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Activation functions enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@unique\n",
    "class Activation(Enum):\n",
    "    SIGMOID = 1\n",
    "    TANH = 2\n",
    "    RELU = 3\n",
    "    LEAKY_RELU = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = train_images.shape[0]\n",
    "LAYERS = 3\n",
    "LAYER_UNITS = np.array([16, 10, 10], dtype=np.uint32)\n",
    "LAYER_ACTIVATIONS = np.array([Activation['RELU'], Activation['TANH'], Activation['SIGMOID']])\n",
    "ALPHA = 6*10e-2\n",
    "LAMBDA_REG = 10e-6\n",
    "ITERATIONS = 50\n",
    "EPSILON = 0.05\n",
    "MINIBATCH_SIZE = 1000\n",
    "\n",
    "EXAMPLES = train_images.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Activation functions and it's derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAKY_RELU_MULTIPLIER = 0.01\n",
    "\n",
    "def linear_func(X_matrix, W_matrix, b_array):\n",
    "    return np.dot(W_matrix, X_matrix) + b_array\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_threshold(z):\n",
    "    return np.round(z)\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def leaky_relu(z):\n",
    "    return np.maximum(LEAKY_RELU_MULTIPLIER * z, z)\n",
    "\n",
    "def derivative_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def derivative_tanh(z):\n",
    "    return 1 - (tanh(z)**2)\n",
    "\n",
    "def derivative_relu(z):\n",
    "    if(z < 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def derivative_leaky_relu(z):\n",
    "    if(z < 0):\n",
    "        return LEAKY_RELU_MULTIPLIER\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "derivative_relu = np.vectorize(derivative_relu)\n",
    "derivative_leaky_relu = np.vectorize(derivative_leaky_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Normalization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(X_matrix):\n",
    "    X_norm = np.zeros(X_matrix.shape)\n",
    "    for i in range(X_matrix.shape[0]):\n",
    "        X_norm[i] = X_matrix[i]/np.maximum(1, np.max(X_matrix[i]))\n",
    "    return X_norm\n",
    "\n",
    "def normalize_input(x_input, X_matrix):\n",
    "    x_norm = np.zeros(x_input.shape)\n",
    "    x_norm = x_input/np.maximum(1, np.max(X_matrix))\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Forward and Backward Propagation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_prop(A_previous, W_layer, b_layer, activationType = Activation['SIGMOID']):\n",
    "    Z_layer = linear_func(A_previous, W_layer, b_layer)\n",
    "    if (activationType == Activation['SIGMOID']):\n",
    "        A_layer = sigmoid(Z_layer)\n",
    "    elif (activationType == Activation['TANH']):\n",
    "        A_layer = tanh(Z_layer)\n",
    "    elif (activationType == Activation['RELU']):\n",
    "        A_layer = relu(Z_layer)\n",
    "    elif (activationType == Activation['LEAKY_RELU']):\n",
    "        A_layer = leaky_relu(Z_layer)\n",
    "    else:\n",
    "        A_layer = sigmoid(Z_layer)\n",
    "    return A_layer, Z_layer\n",
    "\n",
    "def back_prop(dA_layer, A_previous, Z_layer, W_layer, b_layer, activationType = Activation['SIGMOID']):\n",
    "    if (activationType == Activation['SIGMOID']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_sigmoid(Z_layer))\n",
    "    elif (activationType == Activation['TANH']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_tanh(Z_layer))\n",
    "    elif (activationType == Activation['RELU']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_relu(Z_layer))\n",
    "    elif (activationType == Activation['LEAKY_RELU']):\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_leaky_relu(Z_layer))\n",
    "    else:\n",
    "        dZ_layer = np.multiply(dA_layer, derivative_sigmoid(Z_layer))\n",
    "    \n",
    "    dW_layer = np.dot(dZ_layer, np.transpose(A_previous))/dZ_layer.shape[1]\n",
    "    db_layer = np.sum(dZ_layer, axis = 1, keepdims = True)/dZ_layer.shape[1]\n",
    "    dA_previous = np.dot(np.transpose(W_layer), dZ_layer)\n",
    "\n",
    "    return dA_previous, dW_layer, db_layer   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, b,\n",
    "            layers = LAYERS,\n",
    "            layer_activations = LAYER_ACTIVATIONS):\n",
    "    A = X\n",
    "    for i in range(1, layers+1):\n",
    "        A, z = fwd_prop(A, W[i], b[i], layer_activations[i-1])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, y, W, b, lambda_reg = LAMBDA_REG):\n",
    "    y_prediction = predict(X, W, b)\n",
    "    regularization = 0\n",
    "    loss = (1/2)*((y_prediction - y)**2)\n",
    "    for i in W:\n",
    "        regularization += np.sum(i**2)\n",
    "    cost = (np.sum(loss, axis = 1, keepdims=True)/y.shape[1]) + ((lambda_reg/(2*y.shape[1]))*regularization)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Fit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y,\n",
    "        W_previous = None,\n",
    "        b_previous = None,\n",
    "        features = FEATURES,\n",
    "        layers = LAYERS,\n",
    "        layer_units = LAYER_UNITS,\n",
    "        layer_activations = LAYER_ACTIVATIONS,\n",
    "        examples = EXAMPLES,\n",
    "        alpha = ALPHA,\n",
    "        lambda_reg = LAMBDA_REG,\n",
    "        iterations = ITERATIONS,\n",
    "        epsilon = EPSILON,\n",
    "        mb_size = MINIBATCH_SIZE):\n",
    "    \n",
    "    W = {1: np.random.randn(layer_units[0], features) * np.sqrt(2/features)}\n",
    "    dW = {1: np.zeros([layer_units[0], features])}\n",
    "    b = {1:np.random.randn(layer_units[0], 1)}\n",
    "    db = {1: np.zeros([layer_units[0], 1])}\n",
    "    Z = {0: X}\n",
    "    A = {0: X}\n",
    "    dA = {0: np.array([])}\n",
    "    for k in range(layers - 1):\n",
    "        W[k+2] = np.random.randn(layer_units[k+1], layer_units[k]) * np.sqrt(1/layer_units[k])\n",
    "        dW[k+2] = np.zeros([layer_units[k+1], layer_units[k]])\n",
    "        b[k+2] = np.random.randn(layer_units[k+1], 1)\n",
    "        db[k+2] = np.zeros([layer_units[k+1], 1])\n",
    "        Z[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "        A[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "        dA[k+1] = np.zeros([layer_units[k+1], examples])\n",
    "\n",
    "    if(W_previous != None and b_previous != None):\n",
    "        W = W_previous\n",
    "        b = b_previous\n",
    "\n",
    "    cost_points = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        for k in range(int(A[0].shape[1]/mb_size)):\n",
    "\n",
    "            for j in range(layers):\n",
    "                if(j == 0):\n",
    "                    A[j+1], Z[j+1] = fwd_prop(A[j][:, k*mb_size:(k+1)*mb_size], W[j+1], b[j+1], layer_activations[j])\n",
    "                else:\n",
    "                    A[j+1], Z[j+1] = fwd_prop(A[j], W[j+1], b[j+1], layer_activations[j])\n",
    "\n",
    "            dA[layers] = - (y[:, k*mb_size:(k+1)*mb_size]/A[layers]) + ((1-y[:, k*mb_size:(k+1)*mb_size])/(1-A[layers]))\n",
    "\n",
    "            for j in range(layers-1, -1, -1):\n",
    "                if(j == 0):\n",
    "                    dA[j], dW[j+1], db[j+1] = back_prop(dA[j+1], A[j][:, k*mb_size:(k+1)*mb_size], Z[j+1], W[j+1], b[j+1], layer_activations[j])\n",
    "                else:\n",
    "                    dA[j], dW[j+1], db[j+1] = back_prop(dA[j+1], A[j], Z[j+1], W[j+1], b[j+1], layer_activations[j])\n",
    "            \n",
    "            for j in range(1, layers+1):\n",
    "                W[j] = (W[j] * (1 - ((alpha*lambda_reg)/y.shape[1]))) - (alpha*dW[j])\n",
    "                b[j] = b[j] - (alpha*db[j])\n",
    "    \n",
    "            cost_points.append(cost(X[:, k*mb_size:(k+1)*mb_size], y[:, k*mb_size:(k+1)*mb_size], W, b))\n",
    "        \n",
    "        print(np.transpose(cost_points[len(cost_points) - 1]))\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Training the N.N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02838595 0.00926926 0.02244874 0.03357301 0.03288838 0.03475618\n",
      "  0.03298112 0.01877156 0.03540261 0.03400445]]\n",
      "[[0.01153776 0.00430181 0.01045388 0.02855271 0.02579763 0.0319554\n",
      "  0.01008057 0.00990521 0.03226765 0.02990116]]\n",
      "[[0.00739024 0.00317076 0.00666609 0.02754046 0.02207639 0.02840792\n",
      "  0.00652937 0.00711758 0.02555555 0.02166665]]\n",
      "[[0.00638998 0.00302017 0.00615326 0.01819472 0.01318373 0.02578323\n",
      "  0.00546614 0.00514661 0.01751453 0.01411009]]\n",
      "[[0.00713957 0.0029098  0.00617708 0.01222671 0.01016995 0.02321302\n",
      "  0.00507124 0.00389824 0.01338291 0.01164704]]\n",
      "[[0.00717664 0.00265561 0.00591245 0.00866873 0.00863964 0.019426\n",
      "  0.00467583 0.00302212 0.01131041 0.01001315]]\n",
      "[[0.0049384  0.00243479 0.00468598 0.0066115  0.00740585 0.01245288\n",
      "  0.00445424 0.0025841  0.00983235 0.00809878]]\n",
      "[[0.00412734 0.00233047 0.00433735 0.00531642 0.00646199 0.00920302\n",
      "  0.00428593 0.00246999 0.00891885 0.00678709]]\n",
      "[[0.00340474 0.0021213  0.00403341 0.00426504 0.0057418  0.00752432\n",
      "  0.00385511 0.00243596 0.00832628 0.00567702]]\n",
      "[[0.00316721 0.00193024 0.004335   0.00355346 0.00537884 0.00679824\n",
      "  0.00354927 0.00235825 0.00816012 0.00506926]]\n",
      "[[0.00295224 0.00167514 0.00428472 0.00308059 0.0051215  0.00645799\n",
      "  0.00325126 0.00232808 0.00783442 0.0046104 ]]\n",
      "[[0.00278144 0.00151048 0.00390558 0.00271338 0.00480678 0.00599047\n",
      "  0.00298938 0.00230972 0.0074317  0.00419899]]\n",
      "[[0.00264319 0.00133501 0.00358395 0.00246677 0.00451508 0.00549084\n",
      "  0.00285915 0.00228871 0.00700087 0.00393831]]\n",
      "[[0.00254222 0.00126696 0.00345635 0.00222806 0.00435347 0.00505431\n",
      "  0.00281564 0.00227411 0.00674977 0.00370838]]\n",
      "[[0.00241536 0.00114099 0.00326598 0.00200653 0.00422744 0.0046997\n",
      "  0.00279524 0.00224599 0.00649128 0.00354696]]\n",
      "[[0.00232678 0.00106019 0.00314263 0.00187814 0.00405122 0.00446244\n",
      "  0.00272955 0.00218674 0.00622466 0.00343069]]\n",
      "[[0.00226124 0.00102031 0.00316101 0.00183715 0.00408147 0.00431821\n",
      "  0.00279088 0.00219997 0.00611926 0.00333299]]\n",
      "[[0.00203153 0.00111066 0.00303154 0.00165986 0.00390592 0.00404441\n",
      "  0.00280719 0.00217105 0.0059459  0.00318527]]\n",
      "[[0.00193475 0.00128173 0.00311389 0.00169032 0.003906   0.00395354\n",
      "  0.00269951 0.00206539 0.00593796 0.00311195]]\n",
      "[[0.0018764  0.00119284 0.00301484 0.00157048 0.00390737 0.00391789\n",
      "  0.00277536 0.00207767 0.0059116  0.00302435]]\n",
      "[[0.00184122 0.00122843 0.00301264 0.00153603 0.00385471 0.00386479\n",
      "  0.00273657 0.00199624 0.00574613 0.00293409]]\n",
      "[[0.00181287 0.00125044 0.0029792  0.00150905 0.00377406 0.00386494\n",
      "  0.00279777 0.00194815 0.00574652 0.00289586]]\n",
      "[[0.00174592 0.00130801 0.00294155 0.00141004 0.00376104 0.00381198\n",
      "  0.00276553 0.00192196 0.00553648 0.00280088]]\n",
      "[[0.00165859 0.00132425 0.00285427 0.00139068 0.00377019 0.00373574\n",
      "  0.00269276 0.00188152 0.00559989 0.0027141 ]]\n",
      "[[0.00163658 0.0013914  0.00275528 0.00138022 0.00373233 0.00360285\n",
      "  0.00266391 0.00186711 0.00552521 0.00268966]]\n",
      "[[0.00161509 0.0012821  0.0027828  0.00129675 0.00358036 0.00353785\n",
      "  0.00257714 0.00184828 0.00534253 0.00273406]]\n",
      "[[0.00149773 0.00144952 0.00266229 0.00137279 0.00362852 0.00345235\n",
      "  0.00261348 0.00188924 0.00530763 0.00261217]]\n",
      "[[0.00147961 0.00136612 0.00258042 0.00128768 0.00362201 0.00333809\n",
      "  0.00252727 0.0018259  0.00504383 0.00261816]]\n",
      "[[0.00147966 0.00142977 0.00251521 0.00122127 0.0035223  0.00328353\n",
      "  0.00261499 0.00184082 0.00497428 0.00263998]]\n",
      "[[0.00148385 0.00143314 0.00248809 0.00116319 0.00359443 0.00341266\n",
      "  0.00245555 0.00182945 0.00470981 0.00259799]]\n",
      "[[0.00138324 0.00143199 0.00234305 0.0011626  0.00361136 0.00319177\n",
      "  0.00247469 0.00180832 0.00469237 0.00255018]]\n",
      "[[0.00139835 0.00140683 0.00218376 0.00111776 0.00350438 0.00315028\n",
      "  0.00254202 0.00181824 0.00466604 0.00263241]]\n",
      "[[0.00150981 0.00141102 0.00242722 0.00118178 0.00363619 0.00312515\n",
      "  0.00232711 0.00175615 0.00452555 0.00269347]]\n",
      "[[0.00147241 0.00145098 0.00228086 0.00103937 0.00353582 0.00317744\n",
      "  0.00256191 0.00176201 0.00467068 0.00257884]]\n",
      "[[0.00147207 0.0013927  0.00215495 0.00098786 0.0035919  0.00309966\n",
      "  0.00252129 0.00179649 0.00455814 0.00258105]]\n",
      "[[0.00147354 0.00133994 0.00209334 0.000954   0.00352524 0.00311059\n",
      "  0.00241107 0.00173935 0.00434939 0.0025259 ]]\n",
      "[[0.0015132  0.00135329 0.00209688 0.00091214 0.00356862 0.0031367\n",
      "  0.00248946 0.00174149 0.00440154 0.00251241]]\n",
      "[[0.00148624 0.00135116 0.00204916 0.00089102 0.00346449 0.00315233\n",
      "  0.00251113 0.00168455 0.00438832 0.00259979]]\n",
      "[[0.00150639 0.00132525 0.00201947 0.00084208 0.00351487 0.00315413\n",
      "  0.00247367 0.00170553 0.00427461 0.00253652]]\n",
      "[[0.00150074 0.00137886 0.00200266 0.00083683 0.00350965 0.00315993\n",
      "  0.00251092 0.00173028 0.00435817 0.00255474]]\n",
      "[[0.00148586 0.00137936 0.00191656 0.00080264 0.00354356 0.00305113\n",
      "  0.00246917 0.00174727 0.00410004 0.00252648]]\n",
      "[[0.00153678 0.00139057 0.0020025  0.0008159  0.00358138 0.00315659\n",
      "  0.00255061 0.00174354 0.00420646 0.00251182]]\n",
      "[[0.00148595 0.00138336 0.00191    0.00079434 0.00349165 0.00314009\n",
      "  0.00245587 0.00170891 0.00393832 0.00256896]]\n",
      "[[0.00153303 0.00142196 0.00196111 0.0009199  0.00356253 0.0033656\n",
      "  0.00248126 0.00177344 0.00431536 0.0025499 ]]\n",
      "[[0.00164544 0.0015104  0.00240355 0.00085354 0.00351339 0.00324572\n",
      "  0.00243936 0.00158879 0.00394233 0.00292575]]\n",
      "[[0.0015053  0.00142808 0.00194874 0.00091641 0.00345933 0.00320244\n",
      "  0.00241594 0.00169857 0.00405288 0.00258446]]\n",
      "[[0.00148554 0.0013891  0.00178519 0.00080679 0.0034403  0.00308332\n",
      "  0.00238483 0.00173102 0.00389357 0.00263055]]\n",
      "[[0.00148844 0.00141061 0.00176503 0.0007499  0.00349416 0.00311157\n",
      "  0.00241756 0.0017299  0.00372636 0.00265115]]\n",
      "[[0.00145843 0.00135433 0.00176134 0.00076303 0.00348778 0.00316217\n",
      "  0.00230886 0.00171456 0.00366929 0.00268369]]\n",
      "[[0.00151233 0.00139074 0.00181989 0.00073623 0.00338089 0.00317658\n",
      "  0.00230141 0.00164225 0.00379213 0.00271319]]\n"
     ]
    }
   ],
   "source": [
    "train_images_normalized = normalize_dataset(train_images)\n",
    "W_final, b_final = fit(train_images_normalized, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 - Saving Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_save = W_final\n",
    "b_save = b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.isdir(\"./training-checkpoint/\")):\n",
    "    os.mkdir(\"./training-checkpoint/\")\n",
    "\n",
    "#checkpoint_file = open(\"./training-checkpoint/checkpoint.txt\", 'w')\n",
    "for i in W_save:\n",
    "    np.savetxt(f'./training-checkpoint/w{i}.csv', W_save[i], delimiter=',')\n",
    "for i in b_save:\n",
    "    np.savetxt(f'./training-checkpoint/b{i}.csv', b_save[i], delimiter=',')\n",
    "#checkpoint_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 - Loading Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_save = {}\n",
    "b_save = {}\n",
    "for i in range(1, LAYERS + 1):\n",
    "    W_save[i] = np.loadtxt(f'./training-checkpoint/w{i}.csv', delimiter=',')\n",
    "    b_save[i] = np.loadtxt(f'./training-checkpoint/b{i}.csv', delimiter=',')\n",
    "    b_save[i] = np.reshape(b_save[i], (b_save[i].shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 - Measuring accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set prediction: 91.28 %\n"
     ]
    }
   ],
   "source": [
    "test_images_normalized = normalize_input(test_images, train_images)\n",
    "test_outputs = np.transpose(sigmoid_threshold(np.transpose(predict(test_images_normalized, W_save, b_save))))\n",
    "test_comparison = np.array([np.array_equal(test_outputs[:, i], test_labels[:, i]) for i in range(test_outputs.shape[1])])\n",
    "test_accuracy = np.sum(test_comparison)*100/test_comparison.shape[0]\n",
    "print(f\"Accuracy on test set prediction: {test_accuracy} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 - Measuring accuracy on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set prediction: 92.045 %\n"
     ]
    }
   ],
   "source": [
    "train_images_normalized = normalize_dataset(train_images)\n",
    "train_outputs = np.transpose(sigmoid_threshold(np.transpose(predict(train_images_normalized, W_save, b_save))))\n",
    "train_comparison = np.array([np.array_equal(train_outputs[:, i], train_labels[:, i]) for i in range(train_outputs.shape[1])])\n",
    "train_accuracy = np.sum(train_comparison)*100/train_comparison.shape[0]\n",
    "print(f\"Accuracy on train set prediction: {train_accuracy} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17 - Test playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saída esperada: 7\n",
      "Saída predita: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = int(np.round(np.random.rand()*len(test_images_raw)))\n",
    "\n",
    "plt.imshow(test_images_raw[index], cmap='magma')\n",
    "test_sample = normalize_input(test_images[:, index].reshape(test_images[:, index].shape[0], 1), train_images)\n",
    "test_predict = sigmoid_threshold(np.transpose(predict(test_sample, W_save, b_save)))\n",
    "print(f\"Saída esperada: {test_labels_raw[index]}\")\n",
    "for i in range(len(test_predict[0])):\n",
    "    if test_predict[0, i] == 1:\n",
    "        print(f\"Saída predita: {i}\")\n",
    "        break\n",
    "    if(i == 9):\n",
    "        print(f\"Sem predição válida.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "427b8541cfc07e6fbe7ab4a5298567b1b3022ff2b70fdb07d029f33f0434686a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
